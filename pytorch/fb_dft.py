import warnings
import torch


def analysis(x, bfr, w, hop_size, fft_size, shift):
    """
    DFT modulated filter bank analysis function.
    
    Inputs:
        x: input tensor; ideally, its length is a multiple of hop size (or stride).
        bfr: analysis buffer state tensor.
        w: flipped analysis prototype filter. 
        hop_size: hop size.
        fft_size: FFT length.
        shift: the amount of circular shifting.         
    Outputs:
        first: transformed representation in the frequency domain. 
        second: updated analysis buffer state. 
    """
    batch, seq_len = x.shape
    filter_len = len(w)
    if seq_len%hop_size != 0:
        warnings.warn('Sequence length is not a multiple of hop size.')
        
    x = torch.cat([bfr, x], axis=1)
    X = torch.nn.functional.unfold(x[:,None,:,None], (filter_len, 1), stride=hop_size)
    bfr = X[:,hop_size:,-1]
    X = w[None,:,None]*X
    X = torch.reshape(X, [batch, -1, fft_size, seq_len//hop_size])
    X = torch.sum(X, dim=1)
    if shift!=0:
        X = torch.roll(X, shift, dims=1)
    X = torch.fft.rfft(X, dim=1)
    return [X, bfr]


def synthesis(X, bfr, w, hop_size, fft_size):
    """
    DFT modulated filter bank synthesis function. 
    No circular shifting here as for DFT modulation, one always can move all circular shiftings to the analysis side. 
    
    Inputs:
        X: transformed representation in the frequency domain.
        bfr: synthesis buffer state.
        w: synthesis prototype filter. 
        hop_size: hop size or stride. 
        fft_size: FFT length.
        
    Outputs:
        first: recovered representation in the time domain.
        second: updated synthesis buffer state.
    """
    filter_len = len(w)
    batch, _, seq_len = X.shape
    
    y = torch.fft.irfft(X, n=fft_size, dim=1)
    y = w[None,:,None]*torch.tile(y, [1, filter_len//fft_size, 1])
    bfr = torch.cat([bfr, torch.zeros(batch, hop_size, dtype=bfr.dtype, layout=bfr.layout, device=bfr.device)], dim=1)
    y = torch.cat([bfr[:,:,None]+y[:,:,:1], y[:,:,1:]], dim=2)
    y = torch.nn.functional.fold(y, (seq_len*hop_size + filter_len-hop_size, 1), (filter_len, 1), stride=hop_size)
    return [y[:,0,:seq_len*hop_size,0], y[:,0,seq_len*hop_size:,0]]


class Analysis(torch.nn.Module):
    """
    DFT modulated filter bank analysis class. 
    """
    def __init__(self, fb, requires_grad=False):
        """
        fb is a filterbank object generated by my matlab/octave design script.
        """
        super(Analysis, self).__init__()
        self.fft_size = fb['T'][0,0].item()
        self.hop_size = fb['B'][0,0].item()
        self.shift = 1 - fb['i'][0,0].item() - fb['j'][0,0].item()
        self.w = torch.nn.Parameter(torch.Tensor(fb['h'][0,0].squeeze()).flip([0]), 
                                    requires_grad=requires_grad)

    def forward(self, x, bfr=None):
        """
        Transform time domain representation to frequency domain. 
        The analysis buffer is set to zeros if not specified. 
        """
        if bfr is None:
            bfr = torch.zeros(x.shape[0], len(self.w)-self.hop_size, dtype=x.dtype, layout=x.layout, device=x.device)
        return analysis(x, bfr, self.w, self.hop_size, self.fft_size, self.shift)
    
    
class Synthesis(torch.nn.Module):
    """
    DFT modulated filter bank synthesis class.
    """
    def __init__(self, fb, requires_grad=False):
        """
        fb is a filterbank object generated by my matlab/octave design script.
        """
        super(Synthesis, self).__init__()
        self.fft_size = fb['T'][0,0].item()
        self.hop_size = fb['B'][0,0].item()
        self.tau_align = fb['tau0'][0,0].item() - (fb['B'][0,0].item() - 1)
        self.w = torch.nn.Parameter(torch.Tensor(fb['g'][0,0].squeeze()),
                                    requires_grad=requires_grad)

    def forward(self, X, bfr=None):
        """
        Transform frequency domain representation to the time domain. 
        The synthesis buffer is set to zeros if not specified. 
        """
        if bfr is None:
            bfr = torch.zeros(X.shape[0], len(self.w)-self.hop_size, dtype=X.real.dtype, layout=X.layout, device=X.device)
        return synthesis(X, bfr, self.w, self.hop_size, self.fft_size)
